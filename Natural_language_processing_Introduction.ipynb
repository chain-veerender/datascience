{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpVRKB676oQ01ijJB7VzcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chain-veerender/datascience/blob/master/Natural_language_processing_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This session covers the fundamental concepts and algorithms in Natural Language Processing (NLP). The goal of these sessions are to understand text using relevant computational statistics.\n",
        "\n",
        "This course will start with basic text processing techniques (such as regular expressions) and then cover advanced techniques (text classification and topic modeling). The emphasis will be on contemporary best practices in industry, including Deep Learning and text embeddings. Along the way we will touch upon text mining, information retrieval, and computational linguistics.\n",
        "\n",
        "This is curated in a \"buffet\" format, a sample of many things, but we will not discuss \"full\" on any one topic. People get a PhD in each of these individual topics ü•á\n",
        "\n",
        "Remember - A little bit of knowledge and a lot of \"how to\" goes a long way in Data Science.\n",
        "\n",
        "credits: [brianspiering Lecture](https://github.com/brianspiering/nlp-course)"
      ],
      "metadata": {
        "id": "8iGIio-eNS0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![An image](https://lawtomated.com/wp-content/uploads/2019/04/structuredVsUnstructuredIgneos.png)"
      ],
      "metadata": {
        "id": "2GdGL9Y8jWEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image credits: https://lawtomated.com/wp-content/uploads/2019/04/structuredVsUnstructuredIgneos.png"
      ],
      "metadata": {
        "id": "X_jHeoZKkFrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![An image](https://www.oriresults.com/wp-content/uploads/Blog-Whats-Hiding-in-Your-Unstructured-Data-1000x592px.png)"
      ],
      "metadata": {
        "id": "pcDBAK_XkLbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image credits: https://www.oriresults.com/wp-content/uploads/Blog-Whats-Hiding-in-Your-Unstructured-Data-1000x592px.png"
      ],
      "metadata": {
        "id": "OCdSijQ2kdIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to produce significant and actionable insights from text data, it is important to get acquainted with the techniques and principles of Natural Language Processing (NLP).\n",
        "\n",
        "NLP is a branch of data science that consists of systematic processes for analyzing, understanding, and deriving information from the text data in a smart and efficient manner."
      ],
      "metadata": {
        "id": "3pIAIsgvkiqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all libraries here"
      ],
      "metadata": {
        "id": "1zS0j1xIlgzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.wordnet import *\n",
        "from nltk.stem.porter import *\n",
        "from nltk import *\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import re"
      ],
      "metadata": {
        "id": "EWhM_lhKldMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a964a827-0396-421d-b41a-abac39cd8d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Pre-processing**"
      ],
      "metadata": {
        "id": "NDxozsyvlt8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text is the most unstructured form of all the available data, various types of noise are present in it and the data is not readily analyzable without any pre-processing.\n",
        "\n",
        "The entire process of cleaning and standardization of text, making it noise-free and ready for analysis is known as text preprocessing.\n",
        "\n",
        "It consists of 3 steps:\n",
        "\n",
        "* Noise Removal\n",
        "\n",
        "* Lexicon Normalization\n",
        "\n",
        "* Object Standardization\n",
        "\n",
        "![An image](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/11180616/Image-1.png)\n",
        "\n",
        "credits: https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/11180616/Image-1.png\n",
        "\n"
      ],
      "metadata": {
        "id": "4biGzH2gly7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Noise Removal**"
      ],
      "metadata": {
        "id": "1rwNfddCKrEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any piece of text which is not relevant to the context of the data and the end-output can be specified as the noise.\n",
        "\n",
        "For example ‚Äì language stopwords (commonly used words of a language ‚Äì is, am, the, of, in etc), URLs or links, social media entities (mentions, hashtags), punctuations and industry specific words. This step deals with removal of all types of noisy entities present in the text.\n",
        "\n"
      ],
      "metadata": {
        "id": "G81M6klwJG_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample code to remove a regex pattern\n",
        "def remove_symbols(input_text, symbol_pattern):\n",
        "    urls = re.finditer(symbol_pattern, input_text)\n",
        "    for i in urls:\n",
        "        input_text = re.sub(i.group().strip(), '', input_text)\n",
        "    return input_text\n",
        "\n",
        "symbol_pattern = \"#[\\w]*\"\n",
        "\n",
        "remove_symbols(\"remove this #hashtag from this text\", symbol_pattern)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V_c-Vn7KJ3hV",
        "outputId": "0c7709e4-4d41-436c-fdba-f610e7e52bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'remove this  from this text'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lexicon Normalization**\n",
        "\n",
        "Another type of textual noise is about the multiple representations exhibited by single word.\n",
        "\n",
        "For example ‚Äì ‚Äúplay‚Äù, ‚Äúplayer‚Äù, ‚Äúplayed‚Äù, ‚Äúplays‚Äù and ‚Äúplaying‚Äù are the different variations of the word ‚Äì ‚Äúplay‚Äù, Though they mean different but contextually all are similar. The step converts all the disparities of a word into their normalized form (also known as lemma).\n",
        "\n",
        "The most common lexicon normalization practices are :\n",
        "\n",
        "**Stemming:**  Stemming is a rudimentary rule-based process of stripping the suffixes (‚Äúing‚Äù, ‚Äúly‚Äù, ‚Äúes‚Äù, ‚Äús‚Äù etc) from a word.\n",
        "\n",
        "**Lemmatization:** Lemmatization, on the other hand, is an organized & step by step procedure of obtaining the root form of the word, it makes use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations)."
      ],
      "metadata": {
        "id": "RrCoiG0bKzLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lem = WordNetLemmatizer()\n",
        "stem = PorterStemmer()\n",
        "\n",
        "word = \"carrying\"\n",
        "\n",
        "print(\"lemmatized word:\", lem.lemmatize(word, \"v\"))\n",
        "print(\"stemming word:\", stem.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T09vvbEZMDrY",
        "outputId": "20182828-96ea-4d86-8688-524ac8bbca12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmatized word: carry\n",
            "stemming word: carri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object Standardization**\n",
        "\n",
        "Text data often contains words or phrases which are not present in any standard lexical dictionaries. These pieces are not recognized by search engines and models.\n",
        "\n",
        "Some of the examples are ‚Äì acronyms, hashtags with attached words, and colloquial slangs. With the help of regular expressions and manually prepared data dictionaries, this type of noise can be fixed"
      ],
      "metadata": {
        "id": "zYEy54PcNQ5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_dict = {'rt':'Retweet', 'dm':'direct message', \"awsm\" : \"awesome\"}\n",
        "def decode_fullform(input_text):\n",
        "  words = input_text.split()\n",
        "  new_words = []\n",
        "  for word in words:\n",
        "        if word.lower() in lookup_dict:\n",
        "            word = lookup_dict[word.lower()]\n",
        "        else:\n",
        "            word = word\n",
        "        new_words.append(word)\n",
        "        new_text = \" \".join(new_words)\n",
        "  return new_text\n",
        "\n",
        "decode_fullform(\"This is a RT and dm by famous celebrity and this is awsm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GR6d-7O0OPib",
        "outputId": "7e439dca-8297-4f43-c5e0-eded15f9e34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a Retweet and direct message by famous celebrity and this is awesome'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text to Features (Feature Engineering on text data)**\n",
        "\n",
        "1. Syntactical Parsing\n",
        "\n",
        "    1.a Dependency Grammar\n",
        "\n",
        "    1.b Part of Speech Tagging\n",
        "\n",
        "2. Entity Parsing\n",
        "\n",
        "    2.a Phrase Detection\n",
        "\n",
        "    2.b Named Entity Recognition\n",
        "\n",
        "    2.c Topic Modelling\n",
        "\n",
        "    2.d N-Grams\n",
        "\n",
        "3. Statistical features\n",
        "\n",
        "   3.a TF ‚Äì IDF\n",
        "\n",
        "   3.b Frequency / Density Features\n",
        "\n",
        "   3.c Readability Features\n",
        "\n",
        "4. word embeddings"
      ],
      "metadata": {
        "id": "NH1gvs8ORggH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Syntactic Parsing**"
      ],
      "metadata": {
        "id": "5ZunbG2KdpNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntactical parsing involves the analysis of words in the sentence for grammar and their arrangement in a manner that shows the relationships among the words."
      ],
      "metadata": {
        "id": "Dlh0wXhIeCmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. A Dependency Trees**\n",
        "\n",
        "Sentences are composed of some words sewed together. The relationship among the words in a sentence is determined by the basic dependency grammar. Dependency grammar is a class of syntactic text analysis that deals with (labeled) asymmetrical binary relations between two lexical items (words). Every relation can be represented in the form of a triplet (relation, governor, dependent). For example: consider the sentence ‚Äì ‚ÄúBills on ports and immigration were submitted by Senator Brownback, Republican of Kansas.‚Äù\n",
        "\n",
        "![An image](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/11181146/image-2.png)\n",
        "\n",
        "Image Credits: https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/11181146/image-2.png\n",
        "\n",
        "The tree shows that ‚Äúsubmitted‚Äù is the root word of this sentence, and is linked by two sub-trees (subject and object subtrees). Each subtree is a itself a dependency tree with relations such as ‚Äì (‚ÄúBills‚Äù <-> ‚Äúports‚Äù <by> ‚Äúproposition‚Äù relation), (‚Äúports‚Äù <-> ‚Äúimmigration‚Äù <by> ‚Äúconjugation‚Äù relation)\n",
        "\n",
        "This type of tree, when parsed recursively in top-down manner gives grammar relation triplets as output which can be used as features for many nlp problems like entity wise sentiment analysis, actor & entity identification, and text classification.\n",
        "\n",
        "**1.B Part of speech tagging**\n",
        "\n",
        "Apart from the grammar relations, every word in a sentence is also associated with a part of speech (pos) tag (nouns, verbs, adjectives, adverbs etc). The pos tags defines the usage and function of a word in the sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "0S6wi7vMeIdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am learning Natural Language Processing at Prime Classes\"\n",
        "tokens = word_tokenize(text)\n",
        "print(pos_tag(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5LZgNENiGPH",
        "outputId": "88be6126-a3b7-498d-be06-194d1d690845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRP'), ('am', 'VBP'), ('learning', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('at', 'IN'), ('Prime', 'NNP'), ('Classes', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credits: https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/"
      ],
      "metadata": {
        "id": "A8XNPez0jQNq"
      }
    }
  ]
}